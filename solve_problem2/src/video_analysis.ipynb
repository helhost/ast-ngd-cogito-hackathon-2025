{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import joblib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 26 classes: ['4011' '4015' '4088' '4196' '7020097009819' '7020097026113'\n",
      " '7023026089401' '7035620058776' '7037203626563' '7037206100022'\n",
      " '7038010009457' '7038010013966' '7038010021145' '7038010054488'\n",
      " '7038010068980' '7039610000318' '7040513000022' '7040513001753'\n",
      " '7040913336684' '7044610874661' '7048840205868' '7071688004713'\n",
      " '7622210410337' '90433917' '90433924' '94011']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Load model and label encoder\n",
    "# -------------------------------\n",
    "model_path = '../../solve_problem1/out/efficientnet_best_model.h5'\n",
    "encoder_path = '../../solve_problem1/out/label_encoder.pkl'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Error: Model not found at {model_path}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if not os.path.exists(encoder_path):\n",
    "    print(f\"Error: Label encoder not found at {encoder_path}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "model = load_model(model_path)\n",
    "label_encoder = joblib.load(encoder_path)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Loaded model with {num_classes} classes: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess the image for the model.\n",
    "    Args:\n",
    "        img: Input image (numpy array).\n",
    "        target_size: Target size for resizing the image.\n",
    "    Returns:\n",
    "        Preprocessed image (numpy array).\n",
    "    \"\"\"\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
    "    return np.expand_dims(img_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Parameters\n",
    "# -------------------------------\n",
    "video_name = 'Varer dobbelt 480P.mp4'\n",
    "video_path = '../../data/videos/' + video_name\n",
    "output_receipt_file = f'../out/receipt_{video_name}.csv'\n",
    "\n",
    "area_threshold = 2000\n",
    "distance_threshold = 60\n",
    "disappearance_threshold = 1.0\n",
    "confidence_threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame dimensions: 852 x 480\n",
      "Video FPS: 30.0\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Open video\n",
    "# -------------------------------\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error: Cannot read the video.\")\n",
    "    cap.release()\n",
    "    sys.exit(1)\n",
    "\n",
    "frame_height, frame_width = first_frame.shape[:2]\n",
    "print(f\"Frame dimensions: {frame_width} x {frame_height}\")\n",
    "print(f\"Video FPS: {fps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROI -> X:283, Y:240, Width:283, Height:240\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Define ROI (Region of Interest)\n",
    "# -------------------------------\n",
    "roi_y = int(frame_height * 0.5)\n",
    "roi_h = int(frame_height * 0.5)\n",
    "roi_x = int(frame_width * 0.333)\n",
    "roi_w = int(frame_width * 0.333)\n",
    "\n",
    "print(f\"Using ROI -> X:{roi_x}, Y:{roi_y}, Width:{roi_w}, Height:{roi_h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Initialize background subtractor\n",
    "# -------------------------------\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=True)\n",
    "\n",
    "active_detections = []\n",
    "detections_by_frame = []\n",
    "def euclidean_distance(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Main loop\n",
    "# -------------------------------\n",
    "frame_number = 0\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_number += 1\n",
    "    current_time = frame_number / fps\n",
    "    roi_frame = frame[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w]\n",
    "\n",
    "    fgmask = fgbg.apply(roi_frame)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_DILATE, kernel, iterations=2)\n",
    "\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    detections_in_frame = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > area_threshold:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            crop = roi_frame[y:y+h, x:x+w]\n",
    "            if crop.size == 0:\n",
    "                continue\n",
    "            processed_crop = preprocess_image(crop)\n",
    "            preds = model.predict(processed_crop, verbose=0)\n",
    "            conf = np.max(preds)\n",
    "            if conf < confidence_threshold:\n",
    "                continue\n",
    "            pred_class = np.argmax(preds, axis=1)[0]\n",
    "            label = label_encoder.classes_[pred_class]\n",
    "            centroid = (x + w // 2, y + h // 2)\n",
    "            detections_in_frame.append({'label': label, 'centroid': centroid, 'bbox': (x, y, w, h), 'conf': conf})\n",
    "\n",
    "            real_x = x + roi_x\n",
    "            real_y = y + roi_y\n",
    "            cv2.rectangle(frame, (real_x, real_y), (real_x+w, real_y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{label} ({conf:.2f})\", (real_x, real_y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            \n",
    "    detections_by_frame.append(([{'label': det['label'], 'conf': det['conf']} for det in detections_in_frame], current_time))\n",
    "\n",
    "    for det in detections_in_frame:\n",
    "        matched = False\n",
    "        for active in active_detections:\n",
    "            if det['label'] == active['label']:\n",
    "                distance = euclidean_distance(det['centroid'], active['centroid'])\n",
    "                if distance < distance_threshold:\n",
    "                    active['centroid'] = det['centroid']\n",
    "                    active['last_seen_time'] = current_time\n",
    "                    matched = True\n",
    "                    break\n",
    "        if not matched:\n",
    "            active_detections.append({\n",
    "                'label': det['label'],\n",
    "                'centroid': det['centroid'],\n",
    "                'last_seen_time': current_time,\n",
    "                'bbox': det['bbox']\n",
    "            })\n",
    "\n",
    "    for active in active_detections.copy():\n",
    "        if current_time - active['last_seen_time'] > disappearance_threshold:\n",
    "            product_label = active['label']\n",
    "            active_detections.remove(active)\n",
    "\n",
    "    cv2.imshow('Full Frame with Detections', frame)\n",
    "    cv2.imshow('ROI Frame', roi_frame)\n",
    "    cv2.imshow('Foreground Mask', fgmask)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break # quit on 'q' press\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# Finalize lingering detections\n",
    "for active in active_detections:\n",
    "    product_label = active['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to chedck future frames for the same product\n",
    "def check_future_frames(label, frame_number, frame_depth=10):\n",
    "    # check average confidence for the label in future 10 frames\n",
    "    future_frames = detections_by_frame[frame_number:frame_number + frame_depth]\n",
    "    confidences = []\n",
    "    for ff in future_frames:\n",
    "        for detection in ff[0]:\n",
    "            if detection['label'] == label:\n",
    "                confidences.append(detection['conf'])\n",
    "    return np.mean(confidences) if confidences else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_safe_period_coming(frame_number, frame_depth=10, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Check if the best average confidence for any label in the next frame_depth frames\n",
    "    is below the given threshold. Used to determine if it's safe to re-enable detection.\n",
    "    \"\"\"\n",
    "    future_frames = detections_by_frame[frame_number:frame_number + frame_depth]\n",
    "    label_confidences = {}\n",
    "\n",
    "    for ff in future_frames:\n",
    "        for detection in ff[0]:\n",
    "            label = detection['label']\n",
    "            conf = detection['conf']\n",
    "            if label not in label_confidences:\n",
    "                label_confidences[label] = []\n",
    "            label_confidences[label].append(conf)\n",
    "\n",
    "    if not label_confidences:\n",
    "        return True  # no detections = safe\n",
    "\n",
    "    best_avg_conf = max(\n",
    "        np.mean(conf_list) for conf_list in label_confidences.values()\n",
    "    )\n",
    "    return best_avg_conf < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt = []\n",
    "\n",
    "plu_mapping = {\n",
    "    '4011': 'Bananer Bama',\n",
    "    '4015': 'Epler Røde',\n",
    "    '4088': 'Paprika Rød',\n",
    "    '4196': 'Appelsin',\n",
    "    '94011': 'Bananer Økologisk',\n",
    "    '90433917': 'Red Bull Regular 250ml boks',\n",
    "    '90433924': 'Red Bull Sukkerfri 250ml boks',\n",
    "    '7020097009819': 'Karbonadedeig 5% u/Salt og Vann 400g Meny',\n",
    "    '7020097026113': 'Kjøttdeig Angus 14% 400g Meny',\n",
    "    '7023026089401': 'Ruccula 65g Grønn&Frisk',\n",
    "    '7035620058776': 'Rundstykker Grove Fullkorn m/Frø Rustikk 6stk 420g',\n",
    "    '7037203626563': 'Leverpostei Ovnsbakt Orginal 190g Gilde',\n",
    "    '7037206100022': 'Kokt Skinke Ekte 110g Gilde',\n",
    "    '7038010009457': 'Yoghurt Skogsbær 4x150g Tine',\n",
    "    '7038010013966': 'Norvegia 26% skivet 150g Tine',\n",
    "    '7038010021145': 'Jarlsberg 27% skivet 120g Tine',\n",
    "    '7038010054488': 'Cottage Cheese Mager 2% 400g Tine',\n",
    "    '7038010068980': 'Yt Protein Yoghurt Vanilje 430g Tine',\n",
    "    '7039610000318': 'Frokostegg Frittgående L 12stk Prior',\n",
    "    '7040513000022': 'Gulrot 750g Beger',\n",
    "    '7040513001753': 'Gulrot 1kg pose First Price',\n",
    "    '7040913336684': 'Evergood Classic Filtermalt 250g',\n",
    "    '7044610874661': 'Pepsi Max 0,5l flaske',\n",
    "    '7048840205868': 'Frokostyoghurt Skogsbær 125g pose Q',\n",
    "    '7071688004713': 'Original Havsalt 190g Sørlandschips',\n",
    "    '7622210410337': 'Kvikk Lunsj 3x47g Freia'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_number = 0\n",
    "enccountered_safe_period = True\n",
    "\n",
    "while frame_number < len(detections_by_frame):\n",
    "\n",
    "    if not enccountered_safe_period:\n",
    "        if is_safe_period_coming(frame_number, 30):\n",
    "            enccountered_safe_period = True\n",
    "            frame_number += 30\n",
    "        else :\n",
    "            frame_number += 5\n",
    "        continue\n",
    "\n",
    "    dbf = detections_by_frame[frame_number]\n",
    "    current_detections = dbf[0]\n",
    "    time = dbf[1]\n",
    "\n",
    "    confidences = []\n",
    "    for detection in current_detections:\n",
    "        label = detection['label']\n",
    "        future_conf = check_future_frames(label, frame_number, 20)\n",
    "        confidences.append((label, future_conf))\n",
    "    \n",
    "    if confidences:\n",
    "        max_label = max(confidences, key=lambda x: x[1])\n",
    "        if max_label[1] > 0.98:\n",
    "            receipt.append((plu_mapping[max_label[0]], time))\n",
    "            frame_number += 10\n",
    "            enccountered_safe_period = False\n",
    "            continue\n",
    "    frame_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receipt:\n",
      "Red Bull Sukkerfri 250ml boks, 2.47 seconds\n",
      "Bananer Økologisk, 12.37 seconds\n",
      "Norvegia 26% skivet 150g Tine, 15.10 seconds\n",
      "Paprika Rød, 19.23 seconds\n",
      "Red Bull Regular 250ml boks, 38.43 seconds\n",
      "Epler Røde, 42.73 seconds\n",
      "Red Bull Sukkerfri 250ml boks, 47.27 seconds\n",
      "Red Bull Regular 250ml boks, 55.00 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Receipt:\")\n",
    "for item in receipt:\n",
    "    print(f\"{item[0]}, {item[1]:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receipt saved to ../out/receipt_Varer dobbelt 480P.mp4.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Format Time column to two decimals\n",
    "receipt_df = pd.DataFrame(receipt, columns=['Product', 'Time'])\n",
    "receipt_df['Time'] = receipt_df['Time'].map(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "# Save to CSV\n",
    "receipt_df.to_csv(output_receipt_file, index=False)\n",
    "print(f\"Receipt saved to {output_receipt_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
